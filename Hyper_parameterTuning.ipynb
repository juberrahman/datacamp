{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyper-parameterTuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOQ+qJGz8XARcGwKBfl5pl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juberrahman/datacamp/blob/master/Hyper_parameterTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdwjdefXjkiM",
        "colab_type": "text"
      },
      "source": [
        "## Parameter and hyper-parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRc_9Lpnbf-h",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERUXzYaUa_m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list of original variable names from the training DataFrame\n",
        "original_variables = X_train.columns\n",
        "\n",
        "# Extract the coefficients of the logistic regression estimator\n",
        "model_coefficients = log_reg_clf.coef_[0]\n",
        "\n",
        "# Create a dataframe of the variables and coefficients & print it out\n",
        "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
        "print(coefficient_df)\n",
        "\n",
        "# Print out the top 3 positive variables\n",
        "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, ascending=False)[0:3]\n",
        "print(top_three_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEPANmxQcLHh",
        "colab_type": "text"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDjX6gSTbSkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the 7th (index 6) tree from the random forest\n",
        "chosen_tree = rf_clf.estimators_[6]\n",
        "\n",
        "# Visualize the graph using the provided image\n",
        "imgplot = plt.imshow(tree_viz_image)\n",
        "plt.show()\n",
        "\n",
        "# Extract the parameters and level of the top (index 0) node\n",
        "split_column = chosen_tree.tree_.feature[0]\n",
        "split_column_name = X_train.columns[split_column]\n",
        "split_value = chosen_tree.tree_.threshold[0]\n",
        "\n",
        "# Print out the feature and level\n",
        "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yS_GyRxjvZR",
        "colab_type": "text"
      },
      "source": [
        "Hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BabnX0qEcOD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  confusion_matrix(y_test, rf_old_predictions),\n",
        "  accuracy_score(y_test, rf_old_predictions))) \n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Assess the new model (using new predictions!)\n",
        "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, rf_new_predictions))\n",
        "print(\"Accuracy Score: \\n\\n\", accuracy_score(y_test, rf_new_predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIRk36k14YSG",
        "colab_type": "text"
      },
      "source": [
        "Hyperparameters of KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izsxke-04PYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a knn estimator for each value of n_neighbours\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "# Fit each to the training data & produce predictions\n",
        "knn_5_predictions = knn_5.fit(X_train, y_train).predict(X_test)\n",
        "knn_10_predictions = knn_10.fit(X_train, y_train).predict(X_test)\n",
        "knn_20_predictions = knn_20.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Get an accuracy score for each of the models\n",
        "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
        "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
        "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
        "print(\"The accuracy of 5, 10, 20 neighbours was {}, {}, {}\".format(knn_5_accuracy,knn_10_accuracy,knn_20_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnCatcWh6Uuq",
        "colab_type": "text"
      },
      "source": [
        "Automating Hyperparameter Choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0uaa8z5Rdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the learning rates & results storage\n",
        "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
        "results_list = []\n",
        "\n",
        "# Create the for loop to evaluate model predictions for each learning rate\n",
        "for lr in learning_rates:\n",
        "    model = GradientBoostingClassifier(learning_rate=lr)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    # Save the learning rate and accuracy score\n",
        "    results_list.append([lr, accuracy_score(y_test, predictions)])\n",
        "\n",
        "# Gather everything into a DataFrame\n",
        "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
        "print(results_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7Oi5f_X_L72",
        "colab_type": "text"
      },
      "source": [
        "building learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub6ZAVgv-aKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the learning rates & accuracies list\n",
        "learn_rates = np.linspace(0.01, 2, num=30)\n",
        "accuracies = []\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rates:\n",
        "  \t# Create the model, predictions & save the accuracies as before\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    accuracies.append(accuracy_score(y_test, predictions))\n",
        "\n",
        "# Plot results    \n",
        "plt.plot(learn_rates, accuracies)\n",
        "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erp9b5NuAg3k",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSGObeNzAibI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the function\n",
        "def gbm_grid_search(learn_rate, max_depth):\n",
        "\n",
        "\t# Create the model\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth)\n",
        "    \n",
        "    # Use the model to make predictions\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # Return the hyperparameters and score\n",
        "    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei7gDRZ9FAps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the relevant lists\n",
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2, 4, 6]\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
        "\n",
        "# Print the results\n",
        "print(results_list)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYhazwA_ORW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extend the hyper-prams list\n",
        "results_list = []\n",
        "\n",
        "# Create the new list to test\n",
        "subsample_list = [0.4,0.6]\n",
        "\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "    \n",
        "    \t# Extend the for loop\n",
        "        for subsample in subsample_list:\n",
        "        \t\n",
        "            # Extend the results to include the new hyperparameter\n",
        "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
        "            \n",
        "# Print results\n",
        "print(results_list)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e948P6ajICtN",
        "colab_type": "text"
      },
      "source": [
        "GridSearchCV with Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWJz-_KHHZAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bb4e764-4782-4a27-f782-34579214cd71"
      },
      "source": [
        "# Create a Random Forest Classifier with specified criterion\n",
        "rf_class = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': (2, 4, 8, 15), 'max_features': ('auto','sqrt')} \n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_rf_class = GridSearchCV(\n",
        "    estimator=rf_class,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=4,\n",
        "    cv=5,\n",
        "    refit=True, return_train_score=True)\n",
        "print(grid_rf_class)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvOvU98JDwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the cv_results property into a dataframe & print it out\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "# Extract and print the column with a dictionary of hyperparameters used\n",
        "column = cv_results_df.loc[:, ['params']]\n",
        "print(column)\n",
        "\n",
        "# Extract and print the row that had the best mean test score\n",
        "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\n",
        "print(best_row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRA7Qcw9Fh7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the ROC_AUC score from the best-performing square\n",
        "best_score = grid_rf_class.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Create a variable from the row related to the best-performing square\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
        "print(best_row)\n",
        "\n",
        "# Get the n_estimators parameter from the best-performing square and print\n",
        "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
        "print(best_n_estimators)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r0x35OZc0HN",
        "colab_type": "text"
      },
      "source": [
        "Using the best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLT33F5sc1HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See what type of object the best_estimator_ property is\n",
        "print(type(grid_rf_class.best_estimator_))\n",
        "\n",
        "# Create an array of predictions directly using the best_estimator_ property\n",
        "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
        "\n",
        "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Now create a confusion matrix \n",
        "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Get the ROC-AUC score\n",
        "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_WO5CUJdZzc",
        "colab_type": "text"
      },
      "source": [
        "## Random Search CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5m76_oFdONZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list of values for the learning_rate hyperparameter\n",
        "learn_rate_list = list(np.linspace(0.01,1.5,200))\n",
        "\n",
        "# Create a list of values for the min_samples_leaf hyperparameter\n",
        "min_samples_list = list(range(10,41))\n",
        "\n",
        "# Combination list\n",
        "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
        "\n",
        "# Sample hyperparameter combinations for a random search.\n",
        "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
        "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
        "\n",
        "# Print the result\n",
        "print(combinations_random_chosen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlepPKHDgdOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create lists for criterion and max_features\n",
        "criterion_list = [\"gini\", \"entropy\"]\n",
        "max_feature_list = [\"auto\", \"sqrt\", \"log2\", None]\n",
        "\n",
        "# Create a list of values for the max_depth hyperparameter\n",
        "max_depth_list = list(range(3,56))\n",
        "\n",
        "# Combination list\n",
        "combinations_list = [list(x) for x in product(criterion_list, max_feature_list, max_depth_list)]\n",
        "\n",
        "# Sample hyperparameter combinations for a random search\n",
        "combinations_random_chosen = random.sample(combinations_list, 150)\n",
        "\n",
        "# Print the result\n",
        "print(combinations_random_chosen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8f_rhYrgeFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_and_visualize_hyperparameters(n_samples):\n",
        "\n",
        "  # If asking for all combinations, just return the entire list.\n",
        "  if n_samples == len(combinations_list):\n",
        "    combinations_random_chosen = combinations_list\n",
        "  else:\n",
        "    combinations_random_chosen = []\n",
        "    random_combinations_index = np.random.choice(range(0, len(combinations_list)), n_samples, replace=False)\n",
        "    combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
        "    \n",
        "  # Pull out the X and Y to plot\n",
        "  rand_y, rand_x = [x[0] for x in combinations_random_chosen], [x[1] for x in combinations_random_chosen]\n",
        "\n",
        "  # Plot \n",
        "  plt.clf() \n",
        "  plt.scatter(rand_y, rand_x, c=['blue']*len(combinations_random_chosen))\n",
        "  plt.gca().set(xlabel='learn_rate', ylabel='min_samples_leaf', title='Random Search Hyperparameters')\n",
        "  plt.gca().set_xlim(x_lims)\n",
        "  plt.gca().set_ylim(y_lims)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph0HiXWohPXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirm how many hyperparameter combinations & print\n",
        "number_combs = len(combinations_list)\n",
        "print(number_combs )\n",
        "\n",
        "# Sample and visualise specified combinations\n",
        "for x in [50, 500, 1500]:\n",
        "    sample_and_visualize_hyperparameters(x)\n",
        "    \n",
        "# Sample all the hyperparameter combinations & visualise\n",
        "sample_and_visualize_hyperparameters(number_combs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4rfUN8qjc97",
        "colab_type": "text"
      },
      "source": [
        "RandomizedSearchCV with Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ-QdQmh5PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the parameter grid\n",
        "param_grid = {'learning_rate': np.linspace(0.1, 2, 150), 'min_samples_leaf': list(range(20, 65))} \n",
        "\n",
        "# Create a random search object\n",
        "random_GBM_class = RandomizedSearchCV(\n",
        "    estimator = GradientBoostingClassifier(),\n",
        "    param_distributions = param_grid,\n",
        "    n_iter = 10,\n",
        "    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)\n",
        "\n",
        "# Fit to the training data\n",
        "random_GBM_class.fit(X_train, y_train)\n",
        "\n",
        "# Print the values used for both hyperparameters\n",
        "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
        "print(random_GBM_class.cv_results_['param_min_samples_leaf'])\n",
        "print(random_GBM_class.best_score_)\n",
        "print(random_GBM_class.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz0nWLHSfklH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} \n",
        "\n",
        "# Create a random search object\n",
        "random_rf_class = RandomizedSearchCV(\n",
        "    estimator = RandomForestClassifier(n_estimators=80),\n",
        "    param_distributions = param_grid, n_iter = 5,\n",
        "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True)\n",
        "\n",
        "# Fit to the training data\n",
        "random_rf_class.fit(X_train, y_train)\n",
        "\n",
        "# Print the values used for both hyperparameters\n",
        "print(random_rf_class.cv_results_['param_max_depth'])\n",
        "print(random_rf_class.cv_results_['param_max_features'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg5rJy4M1OPt",
        "colab_type": "text"
      },
      "source": [
        "Grid and Random Search Side by Side"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiza_gtKoBik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample grid coordinates\n",
        "grid_combinations_chosen = combinations_list[0:300]\n",
        "\n",
        "# Create a list of sample indexes\n",
        "sample_indexes = list(range(0,len(combinations_list)))\n",
        "\n",
        "# Randomly sample 300 indexes\n",
        "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
        "\n",
        "# Use indexes to create random sample\n",
        "random_combinations_chosen = [combinations_list[index] for index in random_indexes]\n",
        "\n",
        "# Call the function to produce the visualization\n",
        "visualize_search(grid_combinations_chosen, random_combinations_chosen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGLDUww33zCG",
        "colab_type": "text"
      },
      "source": [
        "## Informed search\n",
        "Visualizing coarse to fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhAdIQdk2aX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confirm the size of the combinations_list\n",
        "print(len(combinations_list))\n",
        "\n",
        "# Sort the results_df by accuracy and print the top 10 rows\n",
        "print(results_df.sort_values(by='accuracy', ascending=False).head(10))\n",
        "\n",
        "# Confirm which hyperparameters were used in this search\n",
        "print(results_df.columns)\n",
        "\n",
        "# Call visualize_hyperparameter() with each hyperparameter in turn\n",
        "visualize_hyperparameter('max_depth')\n",
        "visualize_hyperparameter('min_samples_leaf')\n",
        "visualize_hyperparameter('learn_rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrOSHAEU51cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_first():\n",
        "  for name in results_df.columns[0:2]:\n",
        "    plt.clf()\n",
        "    plt.scatter(results_df[name],results_df['accuracy'], c=['blue']*500)\n",
        "    plt.gca().set(xlabel='{}'.format(name), ylabel='accuracy', title='Accuracy for different {}s'.format(name))\n",
        "    plt.gca().set_ylim([0,100])\n",
        "    x_line = 20\n",
        "    if name == \"learn_rate\":\n",
        "      \tx_line = 1\n",
        "    plt.axvline(x=x_line, color=\"red\", linewidth=4)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_second():\n",
        "  for name in results_df2.columns[0:2]:\n",
        "    plt.clf()\n",
        "    plt.scatter(results_df2[name],results_df2['accuracy'], c=['blue']*1000)\n",
        "    plt.gca().set(xlabel='{}'.format(name), ylabel='accuracy', title='Accuracy for different {}s'.format(name))\n",
        "    plt.gca().set_ylim([0,100])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Use the provided function to visualize the first results\n",
        "visualize_first()\n",
        "\n",
        "# Create some combinations lists & combine:\n",
        "max_depth_list = list(range(1,21))\n",
        "learn_rate_list = np.linspace(0.001,1,50)\n",
        "\n",
        "# Call the function to visualize the second results\n",
        "visualize_second() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls291ZTA6vrD",
        "colab_type": "text"
      },
      "source": [
        "Bayesian hyper-parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV6kJg9x6ug8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up space dictionary with specified hyperparameters\n",
        "space = {'max_depth': hp.quniform('max_depth', 2, 10, 2),'learning_rate': hp.uniform('learning_rate', 0.001, 0.9)}\n",
        "\n",
        "# Set up objective function\n",
        "def objective(params):\n",
        "    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n",
        "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params) \n",
        "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=2, n_jobs=4).mean()\n",
        "    loss = 1 - best_score\n",
        "    return loss\n",
        "\n",
        "# Run the algorithm\n",
        "best = fmin(fn=objective,space=space, max_evals=20, rstate=np.random.RandomState(42), algo=tpe.suggest)\n",
        "print(best)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAcRWd8b_wze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahv2SdKk4frg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}